{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonelusetti/phd/NER/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss 2.062427282333374\n",
      "Batch loss 1.2564388513565063\n",
      "Batch loss 0.8411583304405212\n",
      "Batch loss 0.5257542133331299\n",
      "Batch loss 0.3905346989631653\n",
      "Batch loss 0.32734444737434387\n",
      "Batch loss 0.26849621534347534\n",
      "Batch loss 0.25956711173057556\n",
      "Batch loss 0.31483903527259827\n",
      "Batch loss 0.2300548255443573\n",
      "Batch loss 0.2854592204093933\n",
      "Batch loss 0.3234803378582001\n",
      "Batch loss 0.2834727168083191\n",
      "Batch loss 0.29170528054237366\n",
      "Batch loss 0.29983803629875183\n",
      "Batch loss 0.3173629939556122\n",
      "Batch loss 0.2670811712741852\n",
      "Batch loss 0.2601722180843353\n",
      "Batch loss 0.28457918763160706\n",
      "Batch loss 0.22202657163143158\n",
      "Epoch 1, Loss: 0.4655896373093128\n",
      "Batch loss 0.27400001883506775\n",
      "Batch loss 0.26715707778930664\n",
      "Batch loss 0.23720552027225494\n",
      "Batch loss 0.24409396946430206\n",
      "Batch loss 0.19721704721450806\n",
      "Batch loss 0.24021771550178528\n",
      "Batch loss 0.18928980827331543\n",
      "Batch loss 0.19955332577228546\n",
      "Batch loss 0.2585411071777344\n",
      "Batch loss 0.26665833592414856\n",
      "Batch loss 0.2109128087759018\n",
      "Batch loss 0.20328736305236816\n",
      "Batch loss 0.20770511031150818\n",
      "Batch loss 0.2143704742193222\n",
      "Batch loss 0.1911020129919052\n",
      "Batch loss 0.1740853637456894\n",
      "Batch loss 0.17407011985778809\n",
      "Batch loss 0.20494656264781952\n",
      "Batch loss 0.2187747061252594\n",
      "Batch loss 0.29244235157966614\n",
      "Epoch 2, Loss: 0.22328153997659683\n",
      "Batch loss 0.18196815252304077\n",
      "Batch loss 0.22023896872997284\n",
      "Batch loss 0.20678111910820007\n",
      "Batch loss 0.18661242723464966\n",
      "Batch loss 0.1741170436143875\n",
      "Batch loss 0.14509937167167664\n",
      "Batch loss 0.17017605900764465\n",
      "Batch loss 0.17681753635406494\n",
      "Batch loss 0.1710435301065445\n",
      "Batch loss 0.1657128632068634\n",
      "Batch loss 0.14118385314941406\n",
      "Batch loss 0.16630233824253082\n",
      "Batch loss 0.20244181156158447\n",
      "Batch loss 0.15616047382354736\n",
      "Batch loss 0.1743260622024536\n",
      "Batch loss 0.18993067741394043\n",
      "Batch loss 0.17666368186473846\n",
      "Batch loss 0.16642531752586365\n",
      "Batch loss 0.12895427644252777\n",
      "Batch loss 0.15894342958927155\n",
      "Epoch 3, Loss: 0.17299494966864587\n"
     ]
    }
   ],
   "source": [
    "from NER_cadec import training_loop\n",
    "import torch\n",
    "\n",
    "model = training_loop(\"./datasets/cadec\", pos_weight=20, epochs=3, verbose=True)\n",
    "torch.save(model.state_dict(), \"./models/cadec/model_20_3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss 0.18455521762371063\n",
      "Batch loss 0.18826980888843536\n",
      "Batch loss 0.20899246633052826\n",
      "Batch loss 0.15383380651474\n",
      "Batch loss 0.17053207755088806\n",
      "Batch loss 0.1523893177509308\n",
      "Batch loss 0.1769653856754303\n",
      "Batch loss 0.15796466171741486\n",
      "Batch loss 0.1280408799648285\n",
      "Batch loss 0.16899144649505615\n",
      "Batch loss 0.1544807404279709\n",
      "Batch loss 0.14714688062667847\n",
      "Batch loss 0.15071214735507965\n",
      "Batch loss 0.1400219202041626\n",
      "Batch loss 0.1555113047361374\n",
      "Batch loss 0.14277061820030212\n",
      "Batch loss 0.1335197240114212\n",
      "Batch loss 0.15936806797981262\n",
      "Batch loss 0.14995788037776947\n",
      "Batch loss 0.12534719705581665\n",
      "Epoch 1, Loss: 0.1574685774743557\n",
      "Batch loss 0.11098252236843109\n",
      "Batch loss 0.10710667073726654\n",
      "Batch loss 0.12938857078552246\n",
      "Batch loss 0.15596279501914978\n",
      "Batch loss 0.1099814772605896\n",
      "Batch loss 0.13561192154884338\n",
      "Batch loss 0.12550851702690125\n",
      "Batch loss 0.12158408761024475\n",
      "Batch loss 0.10030084103345871\n",
      "Batch loss 0.1276055872440338\n",
      "Batch loss 0.11300407350063324\n",
      "Batch loss 0.11481077969074249\n",
      "Batch loss 0.11684741079807281\n",
      "Batch loss 0.13506338000297546\n",
      "Batch loss 0.11654806137084961\n",
      "Batch loss 0.1130162850022316\n",
      "Batch loss 0.10376396030187607\n",
      "Batch loss 0.10407864302396774\n",
      "Batch loss 0.11078662425279617\n",
      "Batch loss 0.13703688979148865\n",
      "Epoch 2, Loss: 0.11944945491850376\n",
      "Batch loss 0.0884823352098465\n",
      "Batch loss 0.1055305153131485\n",
      "Batch loss 0.09344728291034698\n",
      "Batch loss 0.10629492998123169\n",
      "Batch loss 0.12075019627809525\n",
      "Batch loss 0.08986269682645798\n",
      "Batch loss 0.10462405532598495\n",
      "Batch loss 0.08602677285671234\n",
      "Batch loss 0.10634274780750275\n",
      "Batch loss 0.10027363151311874\n",
      "Batch loss 0.09242583811283112\n",
      "Batch loss 0.10411279648542404\n",
      "Batch loss 0.0820375606417656\n",
      "Batch loss 0.08517002314329147\n",
      "Batch loss 0.07556622475385666\n",
      "Batch loss 0.06867432594299316\n",
      "Batch loss 0.06808358430862427\n",
      "Batch loss 0.0767226293683052\n",
      "Batch loss 0.09908685088157654\n",
      "Batch loss 0.11591266095638275\n",
      "Epoch 3, Loss: 0.09347138293087483\n",
      "Batch loss 0.2786729335784912 | BCE: 0.15570753812789917 | Repair: 0.12296540290117264\n",
      "Batch loss 0.24957768619060516 | BCE: 0.14567787945270538 | Repair: 0.10389980673789978\n",
      "Batch loss 0.2096661478281021 | BCE: 0.1273932158946991 | Repair: 0.08227293193340302\n",
      "Batch loss 0.26414215564727783 | BCE: 0.1434982568025589 | Repair: 0.12064389884471893\n",
      "Batch loss 0.23960405588150024 | BCE: 0.13015946745872498 | Repair: 0.10944458842277527\n",
      "Batch loss 0.2595454454421997 | BCE: 0.14098523557186127 | Repair: 0.11856022477149963\n",
      "Batch loss 0.2626649737358093 | BCE: 0.14276538789272308 | Repair: 0.11989957094192505\n",
      "Batch loss 0.16795757412910461 | BCE: 0.0949719101190567 | Repair: 0.07298566401004791\n",
      "Batch loss 0.2869638204574585 | BCE: 0.16430455446243286 | Repair: 0.12265925109386444\n",
      "Batch loss 0.2728711664676666 | BCE: 0.15171296894550323 | Repair: 0.12115819752216339\n",
      "Batch loss 0.22529473900794983 | BCE: 0.1310938447713852 | Repair: 0.09420089423656464\n",
      "Batch loss 0.2649487853050232 | BCE: 0.1407955437898636 | Repair: 0.1241532415151596\n",
      "Batch loss 0.263952374458313 | BCE: 0.1416643261909485 | Repair: 0.1222880408167839\n",
      "Batch loss 0.19823870062828064 | BCE: 0.10816264152526855 | Repair: 0.09007605165243149\n",
      "Batch loss 0.2084885835647583 | BCE: 0.11694732308387756 | Repair: 0.09154125303030014\n",
      "Batch loss 0.20909321308135986 | BCE: 0.11475922912359238 | Repair: 0.09433399140834808\n",
      "Batch loss 0.21170870959758759 | BCE: 0.11506403982639313 | Repair: 0.09664466977119446\n",
      "Batch loss 0.22753877937793732 | BCE: 0.12242954224348068 | Repair: 0.10510923713445663\n",
      "Batch loss 0.17174622416496277 | BCE: 0.0960007980465889 | Repair: 0.07574542611837387\n",
      "Batch loss 0.27472954988479614 | BCE: 0.14819861948490143 | Repair: 0.12653091549873352\n",
      "Epoch 1, Avg Loss: 0.2374\n",
      "Batch loss 0.16918906569480896 | BCE: 0.09403078258037567 | Repair: 0.07515828311443329\n",
      "Batch loss 0.20096516609191895 | BCE: 0.11524426937103271 | Repair: 0.08572089672088623\n",
      "Batch loss 0.17083893716335297 | BCE: 0.09435015171766281 | Repair: 0.07648878544569016\n",
      "Batch loss 0.16950635612010956 | BCE: 0.09790581464767456 | Repair: 0.071600541472435\n",
      "Batch loss 0.19814224541187286 | BCE: 0.10821013152599335 | Repair: 0.08993211388587952\n",
      "Batch loss 0.1778877228498459 | BCE: 0.09943722933530807 | Repair: 0.07845049351453781\n",
      "Batch loss 0.2332497537136078 | BCE: 0.12303782999515533 | Repair: 0.11021191626787186\n",
      "Batch loss 0.1750185489654541 | BCE: 0.09784669429063797 | Repair: 0.07717185467481613\n",
      "Batch loss 0.1792263686656952 | BCE: 0.09778342396020889 | Repair: 0.0814429521560669\n",
      "Batch loss 0.14411160349845886 | BCE: 0.07960811257362366 | Repair: 0.0645034909248352\n",
      "Batch loss 0.199714794754982 | BCE: 0.10735491663217545 | Repair: 0.09235987812280655\n",
      "Batch loss 0.15029296278953552 | BCE: 0.08657312393188477 | Repair: 0.06371983885765076\n",
      "Batch loss 0.18128086626529694 | BCE: 0.09813323616981506 | Repair: 0.08314763009548187\n",
      "Batch loss 0.16547396779060364 | BCE: 0.09474477916955948 | Repair: 0.07072918862104416\n",
      "Batch loss 0.1761094331741333 | BCE: 0.0972534716129303 | Repair: 0.0788559690117836\n",
      "Batch loss 0.16254158318042755 | BCE: 0.09199859946966171 | Repair: 0.07054298371076584\n",
      "Batch loss 0.14854320883750916 | BCE: 0.08688806742429733 | Repair: 0.06165514141321182\n",
      "Batch loss 0.16134406626224518 | BCE: 0.08915437012910843 | Repair: 0.07218969613313675\n",
      "Batch loss 0.13405904173851013 | BCE: 0.07348161190748215 | Repair: 0.06057743728160858\n",
      "Batch loss 0.10205602645874023 | BCE: 0.05634983628988266 | Repair: 0.04570619389414787\n",
      "Epoch 2, Avg Loss: 0.1700\n",
      "Batch loss 0.14659541845321655 | BCE: 0.08381641656160355 | Repair: 0.06277899444103241\n",
      "Batch loss 0.1378318816423416 | BCE: 0.07991733402013779 | Repair: 0.057914551347494125\n",
      "Batch loss 0.1672833263874054 | BCE: 0.09051978588104248 | Repair: 0.07676354795694351\n",
      "Batch loss 0.16028103232383728 | BCE: 0.09176723659038544 | Repair: 0.06851378828287125\n",
      "Batch loss 0.14121021330356598 | BCE: 0.08111656457185745 | Repair: 0.060093652456998825\n",
      "Batch loss 0.13788947463035583 | BCE: 0.07691558450460434 | Repair: 0.060973890125751495\n",
      "Batch loss 0.18540900945663452 | BCE: 0.0996263325214386 | Repair: 0.08578267693519592\n",
      "Batch loss 0.10776021331548691 | BCE: 0.060404710471630096 | Repair: 0.04735550284385681\n",
      "Batch loss 0.1210009902715683 | BCE: 0.06871960312128067 | Repair: 0.05228138715028763\n",
      "Batch loss 0.12126629054546356 | BCE: 0.06861527264118195 | Repair: 0.052651017904281616\n",
      "Batch loss 0.12426191568374634 | BCE: 0.07111746817827225 | Repair: 0.05314444750547409\n",
      "Batch loss 0.1288091540336609 | BCE: 0.06981047987937927 | Repair: 0.058998674154281616\n",
      "Batch loss 0.17237600684165955 | BCE: 0.10019315034151077 | Repair: 0.07218284904956818\n",
      "Batch loss 0.09768390655517578 | BCE: 0.0554666705429554 | Repair: 0.04221723973751068\n",
      "Batch loss 0.12508171796798706 | BCE: 0.07302773743867874 | Repair: 0.05205398052930832\n",
      "Batch loss 0.11509894579648972 | BCE: 0.0644620731472969 | Repair: 0.05063687264919281\n",
      "Batch loss 0.10571730136871338 | BCE: 0.05984213575720787 | Repair: 0.04587516933679581\n",
      "Batch loss 0.10183703899383545 | BCE: 0.055276501923799515 | Repair: 0.046560537070035934\n",
      "Batch loss 0.11929705739021301 | BCE: 0.06971248984336853 | Repair: 0.04958456754684448\n",
      "Batch loss 0.11961780488491058 | BCE: 0.06749269366264343 | Repair: 0.05212510749697685\n",
      "Epoch 3, Avg Loss: 0.1318\n"
     ]
    }
   ],
   "source": [
    "from loop_loss_repair import training_loop_repair\n",
    "from NER_cadec import EntityMatrixPredictor\n",
    "import torch\n",
    "\n",
    "model = EntityMatrixPredictor(bert_model_name='bert-base-cased')\n",
    "model.load_state_dict(torch.load(\"./models/cadec/model_20_3.pth\"))\n",
    "model = training_loop(\"./datasets/cadec\", model=model, pos_weight=48, epochs=3, verbose=True)\n",
    "torch.save(model.state_dict(), \"./models/cadec/model_15_6.pth\")\n",
    "model = EntityMatrixPredictor(bert_model_name='bert-base-cased')\n",
    "model.load_state_dict(torch.load(\"./models/cadec/model_15_3.pth\"))\n",
    "model = training_loop_repair(\"./datasets/cadec\", model=model, verbose=True, pos_weight=17, epochs=3, repair_loss_weight=1)\n",
    "torch.save(model.state_dict(), \"./models/cadec/model_repair_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(), \"./models/cadec/model_repair_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.11304347826086956, 0.16802721088435374, 0.13515731874145007)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model = EntityMatrixPredictor(bert_model_name=\\'bert-base-cased\\')\\nmodel.load_state_dict(torch.load(\"./models/cadec/model_repair_1.pth\"))\\nevaluation_loop(\"./datasets/cadec\", model)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from NER_cadec import evaluation_loop\n",
    "from NER_cadec import EntityMatrixPredictor\n",
    "import torch\n",
    "\n",
    "model = EntityMatrixPredictor(bert_model_name='bert-base-cased')\n",
    "model.load_state_dict(torch.load(\"./models/cadec/model_20_3.pth\"))\n",
    "print(evaluation_loop(\"./datasets/cadec\", model))\n",
    "\"\"\"model = EntityMatrixPredictor(bert_model_name='bert-base-cased')\n",
    "model.load_state_dict(torch.load(\"./models/cadec/model_repair_1.pth\"))\n",
    "evaluation_loop(\"./datasets/cadec\", model)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Config name is missing.\nPlease pick one among the available configs: ['Ade_corpus_v2_classification', 'Ade_corpus_v2_drug_ade_relation', 'Ade_corpus_v2_drug_dosage_relation']\nExample of usage:\n\t`load_dataset('ade_corpus_v2', 'Ade_corpus_v2_classification')`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m dataset = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43made_corpus_v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Or a specific community version if available\u001b[39;00m\n\u001b[32m      4\u001b[39m dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m1\u001b[39m:\u001b[32m100\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/phd/NER/.venv/lib/python3.13/site-packages/datasets/load.py:2062\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2057\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   2058\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   2059\u001b[39m )\n\u001b[32m   2061\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2062\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2075\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2076\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   2080\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/phd/NER/.venv/lib/python3.13/site-packages/datasets/load.py:1819\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[39m\n\u001b[32m   1817\u001b[39m builder_cls = get_dataset_builder_class(dataset_module, dataset_name=dataset_name)\n\u001b[32m   1818\u001b[39m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1819\u001b[39m builder_instance: DatasetBuilder = \u001b[43mbuilder_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1825\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mdataset_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1826\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1830\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1833\u001b[39m builder_instance._use_legacy_cache_dir_if_possible(dataset_module)\n\u001b[32m   1835\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/phd/NER/.venv/lib/python3.13/site-packages/datasets/builder.py:343\u001b[39m, in \u001b[36mDatasetBuilder.__init__\u001b[39m\u001b[34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, repo_id, data_files, data_dir, storage_options, writer_batch_size, **config_kwargs)\u001b[39m\n\u001b[32m    341\u001b[39m     config_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata_dir\u001b[39m\u001b[33m\"\u001b[39m] = data_dir\n\u001b[32m    342\u001b[39m \u001b[38;5;28mself\u001b[39m.config_kwargs = config_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28mself\u001b[39m.config, \u001b[38;5;28mself\u001b[39m.config_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_builder_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    352\u001b[39m     \u001b[38;5;66;03m# TODO FOR PACKAGED MODULES IT IMPORTS DATA FROM src/packaged_modules which doesn't make sense\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/phd/NER/.venv/lib/python3.13/site-packages/datasets/builder.py:555\u001b[39m, in \u001b[36mDatasetBuilder._create_builder_config\u001b[39m\u001b[34m(self, config_name, custom_features, **config_kwargs)\u001b[39m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_kwargs:\n\u001b[32m    552\u001b[39m         example_of_usage = (\n\u001b[32m    553\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mload_dataset(\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.repo_id\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.dataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.BUILDER_CONFIGS[\u001b[32m0\u001b[39m].name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    554\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mConfig name is missing.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    557\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease pick one among the available configs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.builder_configs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m             + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mExample of usage:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_of_usage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    559\u001b[39m         )\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    561\u001b[39m     builder_config = \u001b[38;5;28mself\u001b[39m.BUILDER_CONFIGS[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Config name is missing.\nPlease pick one among the available configs: ['Ade_corpus_v2_classification', 'Ade_corpus_v2_drug_ade_relation', 'Ade_corpus_v2_drug_dosage_relation']\nExample of usage:\n\t`load_dataset('ade_corpus_v2', 'Ade_corpus_v2_classification')`"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ade_corpus_v2\")  # Or a specific community version if available\n",
    "dataset[\"train\"][1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_opening_paths(matrix, threshold=0.5, max_distance=10):\n",
    "    \"\"\"\n",
    "    Recursively find all maximal opening paths (as sequences of node indices) in the upper triangle of the matrix.\n",
    "\n",
    "    Args:\n",
    "        matrix (torch.Tensor): A square matrix of shape (N, N)\n",
    "        threshold (float): Minimum value to consider an arc active\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: Only maximal (non-nested) paths represented as lists of node indices.\n",
    "    \"\"\"\n",
    "    n = matrix.size(0)\n",
    "    all_paths = []\n",
    "\n",
    "    def recurse(path, distance=0):\n",
    "        i,j = path[-1]\n",
    "        branches = []\n",
    "        for k in range(i + 1, min(i + distance,n)):\n",
    "            if matrix[j, k] > threshold: \n",
    "                for m in range(k, min(i + distance,n)):\n",
    "                    if matrix[j, m] > threshold: \n",
    "                        branches.append((j, m))\n",
    "                        matrix[j, m] = 0\n",
    "                break\n",
    "        if branches == []: \n",
    "            all_paths.append(path)\n",
    "            return\n",
    "        for j,m in branches:\n",
    "            recurse(path + [(j,m)], distance=distance-m)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, min(i + max_distance, n)):\n",
    "            if matrix[i, j] > threshold:\n",
    "                recurse([(i, j)], distance=max_distance)\n",
    "\n",
    "    return all_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_partitions(lst):\n",
    "    if not lst:\n",
    "        yield []\n",
    "        return\n",
    "    for i in range(1, len(lst) + 1):\n",
    "        first = lst[:i]\n",
    "        for rest in ordered_partitions(lst[i:]):\n",
    "            yield [first] + rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opening_paths_partitions(path):\n",
    "    \"\"\"\n",
    "    Given a forward path as list of arcs (i, j), generate all valid backward-closing partitions.\n",
    "    Each partition is a list of arcs like (to, from) that would close the entity.\n",
    "\n",
    "    Args:\n",
    "        path: List of tuples representing the forward arcs (e.g., [(0,1), (1,2), (2,3)])\n",
    "\n",
    "    Returns:\n",
    "        List[List[Tuple[int, int]]]: All possible backward arcs to close the path\n",
    "    \"\"\"\n",
    "    repairs = []\n",
    "    for p in ordered_partitions(path):\n",
    "        rep = []\n",
    "        for e in p:\n",
    "            rep.append((e[-1][1], e[0][0]))\n",
    "        repairs.append(rep)\n",
    "\n",
    "    return repairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_matrix_lower(logits, threshold=0.5, max_distance=10):\n",
    "    upper = torch.triu(logits, diagonal=1)\n",
    "    paths = find_opening_paths(logits, threshold, max_distance)\n",
    "    for path in paths:\n",
    "        partitions = opening_paths_partitions(path)\n",
    "        partitions_weight = []\n",
    "        for p in partitions:\n",
    "            partitions_weight.append(sum(list(map(lambda cell: 1-logits[cell[0],cell[1]], p))))\n",
    "\n",
    "        for repaired_cell in partitions[partitions_weight.index(min(partitions_weight))]:\n",
    "            logits[repaired_cell[0], repaired_cell[1]] = 1\n",
    "    return torch.tril(logits, diagonal=-1) + upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.9000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "logits = torch.tensor([\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.9],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.9],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "])\n",
    "\n",
    "repair_matrix_lower(logits, threshold=0.5, max_distance=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closing_paths(logits, threshold=0.5, max_distance=10):\n",
    "    \"\"\"\n",
    "    Recursively find all maximal closing paths (as sequences of node indices) in the lower triangle of the matrix.\n",
    "\n",
    "    Args:\n",
    "        matrix (torch.Tensor): A square matrix of shape (N, N)\n",
    "        threshold (float): Minimum value to consider an arc active\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: Only maximal (non-nested) paths represented as lists of node indices.\n",
    "    \"\"\"\n",
    "    n = logits.size(0)\n",
    "    return [(j, i) for i in range(n) for j in range(i + 1, min(i + max_distance, n)) if logits[j, i] > threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closing_path_partitions(path):\n",
    "    i,j = path\n",
    "    partitions = []\n",
    "    for p in ordered_partitions(list(range(i - j))):\n",
    "        k,l = j, j\n",
    "        part = []\n",
    "        for e in p:\n",
    "            k = k + len(e)\n",
    "            part.append((l,k))\n",
    "            l = l + len(e)\n",
    "        partitions.append(part)\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_matrix_upper(logits, threshold=0.5, max_distance=10):\n",
    "    lower = torch.tril(logits, diagonal=-1)\n",
    "    paths = find_closing_paths(logits, threshold, max_distance)\n",
    "    for path in paths:\n",
    "        partitions = closing_path_partitions(path)\n",
    "        partitions_weight = []\n",
    "        for p in partitions:\n",
    "            partitions_weight.append(sum(list(map(lambda cell: 1-logits[cell[0],cell[1]], p))))\n",
    "        for repaired_cell in partitions[partitions_weight.index(min(partitions_weight))]:\n",
    "            logits[repaired_cell[0], repaired_cell[1]] = 1\n",
    "    return lower + torch.triu(logits, diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([\n",
    "    [0.0, 0.2, 0.3, 0.4],\n",
    "    [0.0, 0.0, 0.2, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.2],\n",
    "    [0.9, 0.0, 0.0, 0.0],\n",
    "])\n",
    "\n",
    "repair_matrix_upper(logits, threshold=0.5, max_distance=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
